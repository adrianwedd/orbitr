name: Comprehensive Testing Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run comprehensive tests daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  NODE_VERSION: '18'
  PYTHON_VERSION: '3.11'
  # Test environment variables
  API_KEY: 'test-api-key-secure'
  GENERATION_RATE_LIMIT: '10'
  CACHE_RATE_LIMIT: '30'
  HEALTH_RATE_LIMIT: '60'
  MAX_PROMPT_LENGTH: '500'
  MAX_GENERATION_DURATION: '5.0'
  MAX_CONCURRENT_GENERATIONS: '3'
  GENERATION_TIMEOUT: '30'
  MAX_REQUEST_SIZE: '10485760'
  ENVIRONMENT: 'test'

jobs:
  # Frontend Testing Pipeline
  frontend-tests:
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        test-suite: [unit, performance, memory, integration]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Type checking
      run: npm run type-check

    - name: Lint code
      run: npm run lint

    - name: Run ${{ matrix.test-suite }} tests
      run: |
        case "${{ matrix.test-suite }}" in
          "unit")
            npm run test -- --testPathPattern="__tests__/(lib|components)" --coverage --coverageReporters=lcov
            ;;
          "performance")
            npm run test -- --testPathPattern="__tests__/performance" --runInBand --detectOpenHandles
            ;;
          "memory")
            npm run test -- --testPathPattern="memory-leak" --runInBand --logHeapUsage --detectOpenHandles
            ;;
          "integration")
            npm run test -- --testPathPattern="__tests__/integration" --runInBand --detectOpenHandles
            ;;
        esac

    - name: Upload coverage reports
      if: matrix.test-suite == 'unit'
      uses: codecov/codecov-action@v3
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        file: ./coverage/lcov.info
        flags: frontend
        name: frontend-coverage

    - name: Upload test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: frontend-test-results-${{ matrix.test-suite }}
        path: |
          coverage/
          test-results/
        retention-days: 7

  # Backend Security Testing Pipeline
  backend-security-tests:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Cache Python dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install Python dependencies
      run: |
        cd backend
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-asyncio pytest-mock

    - name: Run security tests
      run: |
        cd backend
        python -m pytest test_security.py -v --tb=short --cov=app --cov-report=xml --cov-report=html

    - name: Run API tests
      run: |
        cd backend
        python -m pytest test_app.py -v --tb=short

    - name: Security scanning with bandit
      run: |
        cd backend
        pip install bandit
        bandit -r . -f json -o bandit-report.json || true

    - name: Upload security test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: backend-security-results
        path: |
          backend/htmlcov/
          backend/coverage.xml
          backend/bandit-report.json
        retention-days: 7

  # Performance Benchmarking
  performance-benchmarks:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Run performance benchmarks
      run: |
        npm run test -- --testPathPattern="performance" --runInBand --verbose --detectOpenHandles
      env:
        NODE_OPTIONS: '--max-old-space-size=8192'

    - name: Generate performance report
      run: |
        mkdir -p performance-reports
        npm run test -- --testPathPattern="load-testing" --runInBand --verbose --json --outputFile=performance-reports/performance-results.json || true

    - name: Upload performance results
      uses: actions/upload-artifact@v4
      with:
        name: performance-benchmarks
        path: performance-reports/
        retention-days: 30

  # End-to-End Integration Tests
  e2e-integration:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    services:
      redis:
        image: redis:6-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install frontend dependencies
      run: npm ci

    - name: Install backend dependencies
      run: |
        cd backend
        pip install -r requirements-minimal.txt
        pip install pytest pytest-asyncio uvicorn

    - name: Start backend server
      run: |
        cd backend
        python app.py &
        sleep 10
      env:
        ENVIRONMENT: test
        API_KEY: test-api-key-secure

    - name: Run integration tests
      run: npm run test -- --testPathPattern="end-to-end" --runInBand --detectOpenHandles

    - name: Upload integration test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: e2e-integration-results
        path: |
          test-results/
          screenshots/
        retention-days: 7

  # Memory Leak Detection
  memory-leak-detection:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js with increased memory
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Run memory leak tests
      run: |
        npm run test -- --testPathPattern="memory-leak" --runInBand --logHeapUsage --detectOpenHandles --forceExit
      env:
        NODE_OPTIONS: '--max-old-space-size=4096 --expose-gc'

    - name: Generate memory report
      run: |
        mkdir -p memory-reports
        echo "Memory leak detection completed" > memory-reports/memory-test-summary.txt

    - name: Upload memory test results
      uses: actions/upload-artifact@v4
      with:
        name: memory-leak-results
        path: memory-reports/
        retention-days: 14

  # Security Vulnerability Scanning
  security-scan:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Run npm audit
      run: |
        npm audit --audit-level=moderate --json > npm-audit-report.json || true

    - name: Run Snyk security scan
      uses: snyk/actions/node@master
      continue-on-error: true
      env:
        SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
      with:
        args: --severity-threshold=medium --json-file-output=snyk-report.json

    - name: Upload security scan results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: security-scan-results
        path: |
          npm-audit-report.json
          snyk-report.json
        retention-days: 30

  # Quality Gate Check
  quality-gate:
    runs-on: ubuntu-latest
    needs: [frontend-tests, backend-security-tests, performance-benchmarks, e2e-integration, memory-leak-detection]
    if: always()
    
    steps:
    - name: Download all test artifacts
      uses: actions/download-artifact@v4

    - name: Evaluate quality metrics
      run: |
        echo "=== Quality Gate Evaluation ==="
        
        # Check if critical tests passed
        if [ "${{ needs.frontend-tests.result }}" != "success" ]; then
          echo "❌ Frontend tests failed"
          exit 1
        fi
        
        if [ "${{ needs.backend-security-tests.result }}" != "success" ]; then
          echo "❌ Security tests failed"
          exit 1
        fi
        
        if [ "${{ needs.e2e-integration.result }}" != "success" ]; then
          echo "❌ Integration tests failed"
          exit 1
        fi
        
        # Performance and memory tests can be warnings
        if [ "${{ needs.performance-benchmarks.result }}" != "success" ]; then
          echo "⚠️  Performance benchmarks had issues"
        fi
        
        if [ "${{ needs.memory-leak-detection.result }}" != "success" ]; then
          echo "⚠️  Memory leak detection had issues"
        fi
        
        echo "✅ Quality gate passed"

    - name: Generate test summary
      run: |
        echo "# Test Summary Report" > test-summary.md
        echo "" >> test-summary.md
        echo "## Test Results" >> test-summary.md
        echo "- Frontend Tests: ${{ needs.frontend-tests.result }}" >> test-summary.md
        echo "- Security Tests: ${{ needs.backend-security-tests.result }}" >> test-summary.md
        echo "- Performance Tests: ${{ needs.performance-benchmarks.result }}" >> test-summary.md
        echo "- Integration Tests: ${{ needs.e2e-integration.result }}" >> test-summary.md
        echo "- Memory Leak Tests: ${{ needs.memory-leak-detection.result }}" >> test-summary.md
        echo "" >> test-summary.md
        echo "## Deployment Status" >> test-summary.md
        if [ "${{ needs.frontend-tests.result }}" = "success" ] && [ "${{ needs.backend-security-tests.result }}" = "success" ] && [ "${{ needs.e2e-integration.result }}" = "success" ]; then
          echo "✅ **READY FOR DEPLOYMENT**" >> test-summary.md
        else
          echo "❌ **NOT READY FOR DEPLOYMENT**" >> test-summary.md
        fi

    - name: Upload test summary
      uses: actions/upload-artifact@v4
      with:
        name: test-summary-report
        path: test-summary.md
        retention-days: 90

  # Deployment Readiness Check
  deployment-readiness:
    runs-on: ubuntu-latest
    needs: [quality-gate]
    if: github.ref == 'refs/heads/main' && needs.quality-gate.result == 'success'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Build frontend
      run: npm run build

    - name: Validate build artifacts
      run: |
        if [ ! -d ".next" ]; then
          echo "❌ Frontend build failed"
          exit 1
        fi
        
        echo "✅ Build artifacts validated"
        echo "✅ Application ready for deployment"

    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: deployment-artifacts
        path: |
          .next/
          backend/
        retention-days: 30